{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88908c3c25435652",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# FINANCE 781:   Exam 2024, Numerical Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca758a8f8051e0c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1cb1a040578df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let y = [4,6,3,6,10] and x = [3,6,9,4,9]. \n",
    "\n",
    "If we perform an ordinary least squares (OLS) regression of y on x, what is the root mean squared error (RMSE) on the training data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45659d70aabbac7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Given data\n",
    "y = np.array([4, 6, 3, 6, 10])\n",
    "x = np.array([3, 6, 9, 4, 9]).reshape(-1, 1)\n",
    "\n",
    "# Fit the OLS regression model\n",
    "model = LinearRegression().fit(x, y)\n",
    "\n",
    "# Predict the y values\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "# Calculate the residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f52a6d076afac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b016c68e42817",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You define PCA_3 as a function that applies principal components analysis (PCA) to a dataset and then retains the first 3 principal components as a new dataset.\n",
    "\n",
    "Consider that you apply PCA_3 to a dataset comprised of stock market returns from companies listed on the S&P 500 index, and you label the resulting dataset df_PC.  \n",
    "\n",
    "If the first principal component in df_PC explains 0.13 of the total variance in the original dataset, what is the maximum proportion of total variance that all 3 principal components in df_PC could explain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a104536524ef967",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_variance = 0.13*3\n",
    "\n",
    "max_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe2e1342e0fa1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202bd1bc6d59678",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following training data consists of two features (\"momentum\" and \"investment\") and a target variable (\"return\"):\n",
    "\n",
    " \n",
    "\n",
    "        momentum            investment           return                                \n",
    "          0.04                0.03                0.07                                \n",
    "          0.06                0.05                0.08                                \n",
    "          0.02                0.03                0.05                                \n",
    "          0.05                0.05                0.06                                \n",
    "          0.04                0.06                0.05                                \n",
    "          0.08                0.09                0.11                                \n",
    "          0.06                0.08                0.06\n",
    "\n",
    " \n",
    "\n",
    "The following regression tree was constructed using the training data above (trained to a maximum depth of 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aaaaa6f645ca50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Image description](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e07f24212db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Based on the tree above and the training data provided, what is the predicted return for a new observation with momentum of 0.07 and investment of 0.06?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f906dda45e794f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Investment ≤ 0.085\n",
    "Momentum > 0.055\n",
    "\n",
    "The training observations that meet these criteria are:\n",
    "\n",
    "Momentum = 0.06, Investment = 0.05, Return = 0.08\n",
    "Momentum = 0.06, Investment = 0.08, Return = 0.06\n",
    "\n",
    "The average return for these observations is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08abd98169fbc2c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ave_return = (0.08+0.06)/2\n",
    "\n",
    "ave_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fafbf4351ed0f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa7c86104e276b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Audacious Capital Partners LLC (ACP) is a hedge fund that takes directional bets based on the expected profitability of stocks.\n",
    "\n",
    "ACP has been developing a neural network that uses R&D Spending and Total Assets to predict the Next Quarter Profit.\n",
    "\n",
    "The neural network architecture is displayed below. It uses ReLU activation for both the Hidden Layer and the Output Layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c2ee1e03dfc47",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Image description](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ad615e7803337",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unfortunately, ACP has had the misfortune of recently hiring an intern.\n",
    "\n",
    "While under the impression that they were working on a test model, the intern added code to the production model that changed all the connection weights (w1 to w6) to 0 and all the biases (b1 to b3) to 1.\n",
    "\n",
    "This updated model was applied to the following data:\n",
    "\n",
    " \n",
    "\n",
    "    R&D Spending\t    Total Assets\t    Next Quarter Profit\n",
    "        300\t            2300\t            211\n",
    "        200\t            4500\t            239\n",
    "        350\t            3100\t            222\n",
    "        420\t            3800\t            191\n",
    " \n",
    "\n",
    "Calculate the RMSE (Root Mean Square Error) of the neural network predictions applied to the data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b2d36ca4cb010",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Actual Next Quarter Profit values\n",
    "actual_profits = np.array([211, 239, 222, 191])\n",
    "\n",
    "# Predicted profits (all are 1 due to the modified model)\n",
    "predicted_profits = np.ones_like(actual_profits)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = np.sqrt(np.mean((actual_profits - predicted_profits) ** 2))\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90290379ca87ba13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e3a4a853abdf4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You have built a neural network using Long-Short Term Memory (LSTM) layers to generate one-step-ahead forecasts of Apple's monthly stock returns.\n",
    "\n",
    "For this regression task, you have decided on a network with three hidden layers and a lookback period of 12 months. \n",
    "\n",
    "The hidden layers are comprised of 23, 14, and 5 LSTM units, respectively.\n",
    "\n",
    "The output layer is a fully connected (i.e., dense) layer with 1 unit and a linear activation function.\n",
    "\n",
    "Following Gu, Kelly, and Xiu (2020, Review of Financial Studies), you have gathered 176 predictor variables to predict the stock returns.\n",
    "\n",
    "How many trainable parameters does the model have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86458a0c0d5feb7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def build_lstm_network(lookback, n_features):\n",
    "\n",
    "    inputs = Input(shape=(lookback, n_features))\n",
    "    x = LSTM(23, return_sequences=True)(inputs)\n",
    "    x = LSTM(14, return_sequences=True)(x)\n",
    "    x = LSTM(5, return_sequences=False)(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_lstm_network(12,176)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02878f9d2caf10",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da80b5cea3c8dec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You wish to use a neural network model to forecast the one-day-ahead realized volatility (RV) of the S&P 500 index using rolling windows.\n",
    "\n",
    "You expect the neural network model to capture the persistence of the RV series.\n",
    "\n",
    "You have preprocessed the data and stored it in the file 'predictors_and_volatility_data.csv'.\n",
    "\n",
    "You have also defined your model in the function 'model_definition()' in the Python file 'ml_model.py', which you can load import to the current script with the 'import ml_model' command.\n",
    "\n",
    "You have started this project by writing the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924298dd2bd3155",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ml_model\n",
    "\n",
    "df = pd.read_csv('predictors_and_volatility_data.csv')\n",
    "\n",
    "window_size = 1000\n",
    "reg_periods = df.shape[0] - window_size\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for n in range(len(df) - reg_periods - 1):\n",
    "    \n",
    "    df_rw = df.iloc[n:reg_periods + n, :].copy()\n",
    "    \n",
    "    train_data, validation_data = train_test_split(df_rw, test_size=0.2)\n",
    "\n",
    "    model = ml_model.model_definition()\n",
    "    model.fit(train_data.drop(\"Target\", axis=1),\n",
    "              train_data[\"Target\"],\n",
    "              validation_data=(validation_data.drop(\"Target\", axis=1), \n",
    "                               validation_data[\"Target\"]),\n",
    "              batch_size=1000,\n",
    "              epochs=20\n",
    "              )\n",
    "\n",
    "    X_test = df.iloc[reg_periods + n: \n",
    "                     reg_periods + n + 1, :].drop(\"Target\", axis=1)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    predictions.append(y_pred.flatten()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2aed5f40405596",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Which line in the code will most likely lead to suboptimal results?\n",
    "\n",
    "You may assume that the batch size, number of epochs, and rolling window length are optimal for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9e7e1e6d7d1d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The line most likely leading to suboptimal results is line 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d0c33e116b005",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(df_rw, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22f35d579de50b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using a simple train-validation split in a rolling window context (with shuffling as this is the default in train_test_split()) may not be suitable for time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dbe4a2ee0df51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d90429043f2eb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Adapting the methodology from Britten-Jones (1999, Journal of Finance), you wish to calculate optimal portfolio weights by rescaling to 100% the coefficients of an l1 penalized linear regression of excess stock returns on a vector of 1’s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2302633bdde419",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You have the following code, which is incomplete as the reg = # [place the correct model here] expression is missing.\n",
    "\n",
    "Keeping all else equal, what is the expected return if you implement an l1 penalized linear regression with a penalization term of 0.0005? Note that the optimal portfolio allows short and long positions in the underlying assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ef02b1177d796",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters for the simulation\n",
    "n_assets = 20       # Number of assets\n",
    "n_periods = 252     # Number of trading days in a year\n",
    "mu = 0.0005         # Mean daily return (roughly 0.05% per day or 12% annually)\n",
    "sigma = 0.02        # Daily volatility (1%)\n",
    "\n",
    "# Simulate daily returns for each asset\n",
    "excess_returns = np.random.normal(loc=0.0005, scale=0.01, size=(252, 20))\n",
    "excess_returns = pd.DataFrame(excess_returns, columns=[f\"Asset_{i+1}\" for i in range(20)])\n",
    "excess_returns['Target'] = 1\n",
    "\n",
    "# training-validation split\n",
    "train_data, validation_data = train_test_split(excess_returns, test_size=0.2, shuffle=False)\n",
    "\n",
    "reg = Lasso(fit_intercept=False, alpha=0.0005, positive=False).fit(train_data.drop(\"Target\", axis=1),\n",
    "                                                                   train_data[\"Target\"])\n",
    "\n",
    "# Original coefficients\n",
    "original_coefs = reg.coef_\n",
    "# Rescale the coefficients so that their sum equals 100\n",
    "rescaled_coefs = original_coefs * (1 / np.sum(original_coefs))\n",
    "\n",
    "expected_return = np.sum(validation_data.drop(\"Target\", axis=1).dot(rescaled_coefs))\n",
    "\n",
    "print(expected_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f1336f910fa35",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a171ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
